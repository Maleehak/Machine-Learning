{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist.loader import MNIST\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from pylab import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    mnist=MNIST('dataset')\n",
    "    ##train data\n",
    "    train_images,train_labels=mnist.load_training()\n",
    "    train_images=np.asarray(train_images)\n",
    "    train_labels=np.asarray(train_labels)\n",
    "    train_labels=train_labels.reshape([train_labels.shape[0],1])\n",
    "    #print(mnist.display(train_images[5]))\n",
    "    ##test data\n",
    "    test_images,test_labels=mnist.load_testing()\n",
    "    test_images=np.asarray(test_images)\n",
    "    test_labels=np.asarray(test_labels)\n",
    "    test_labels=test_labels.reshape([test_labels.shape[0],1])\n",
    "    return train_images,train_labels,test_images,test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(k,Y_train):\n",
    "    Y=[]\n",
    "    #train\n",
    "    for i in range(k):\n",
    "        Y_tr=np.where(Y_train==i,1,0)\n",
    "        Y.append(Y_tr)\n",
    "    Y_arr=np.asarray(Y)\n",
    "    Y_arr=Y_arr.reshape(Y_arr.shape[1],Y_arr.shape[0])\n",
    "    return Y_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_normalization(X_train,X_test):\n",
    "    X_train=X_train/255\n",
    "    X_test=X_test/255\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n,k):\n",
    "    #theta=np.random.randint(-1,2,size=[n,k])\n",
    "    #theta=np.random.randn(n,k)*0.01\n",
    "    theta=np.zeros([n,k])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z)/(np.sum(np.exp(z),axis=1,keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X):\n",
    "    z=np.dot(X,theta)\n",
    "    hx =softmax(z) \n",
    "    print(hx.shape)\n",
    "    return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y,hx):\n",
    "    m=y.shape[0]\n",
    "    #print(m)\n",
    "    return -(1/m)*np.sum(y*np.log(hx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(hx):\n",
    "    m = hx.shape[0]\n",
    "    Y_prediction=hx.argmax(axis=1)\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_of_cost(X,hx,y):\n",
    "    m=y.shape[0]\n",
    "    d_theeta=(1/m)*(np.dot(X.T,(hx-y)))\n",
    "    return d_theeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y_actual, Y_predicted):\n",
    "    classes = 10\n",
    "    Y_actual=Y_actual.reshape(Y_actual.shape[0])\n",
    "    Y_predicted=Y_predicted.reshape(Y_predicted.shape[0])\n",
    "    confusion_mtx=np.bincount(Y_actual * classes + Y_predicted).reshape((classes, classes))\n",
    "    return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(alpha,X_train,Y_train,X_test,Y_test,iterations):\n",
    "    m=Y_train.shape[0]\n",
    "    k=10\n",
    "    costs=[]\n",
    "    Y_train=one_vs_all(k,Y_train)\n",
    "    theta=initialize_parameters(X_train.shape[1],k)\n",
    "    for i in range(iterations):\n",
    "        z=np.dot(X_train,theta)\n",
    "        hx=softmax(z)\n",
    "        J=cost(Y_train,hx)\n",
    "        der=derivative_of_cost(X_train,hx,Y_train)\n",
    "        theta=theta-(alpha)*(der)\n",
    "        i=i+1\n",
    "        if i % 50 == 0:\n",
    "            costs.append(J)\n",
    "            print(\"cost after \"+str(i)+\"  iterations: \"+str(J))\n",
    "    #train        \n",
    "    hx_train = hypothesis(theta, X_train)\n",
    "    Y_predicted_train=predict(hx_train)\n",
    "    Y_predicted_train=Y_predicted_train.reshape(1,Y_predicted_train.shape[0])\n",
    "    ##test\n",
    "    hx_test = hypothesis(theta, X_test)\n",
    "    Y_predicted_test=predict(hx_test)\n",
    "    Y_predicted_test=Y_predicted_test.reshape(1,Y_predicted_test.shape[0])\n",
    "    return Y_predicted_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_test,Y_test=load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x143b2f21e88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view data\n",
    "print(Y_train[3])\n",
    "imshow(X_train[3,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "X_train,X_test=max_normalization(X_train,X_test)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append train\n",
    "X=np.ones([X_train.shape[0],1]) \n",
    "X_train=np.append(X,X_train,axis=1) #(m,n)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append test\n",
    "X=np.ones([X_test.shape[0],1]) \n",
    "X_test=np.append(X,X_test,axis=1) #(m,n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 50  iterations: 2.300610879615169\n",
      "cost after 100  iterations: 2.2994533074949755\n",
      "cost after 150  iterations: 2.2985694600077027\n",
      "cost after 200  iterations: 2.297837877190446\n",
      "cost after 250  iterations: 2.297206023350288\n",
      "cost after 300  iterations: 2.296645159652078\n",
      "cost after 350  iterations: 2.296137762610593\n",
      "cost after 400  iterations: 2.29567235115804\n",
      "cost after 450  iterations: 2.2952409827939397\n",
      "cost after 500  iterations: 2.2948379208378507\n",
      "cost after 550  iterations: 2.2944588741080736\n",
      "cost after 600  iterations: 2.29410053842568\n",
      "cost after 650  iterations: 2.2937603071639927\n",
      "cost after 700  iterations: 2.2934360813499106\n",
      "cost after 750  iterations: 2.2931261409255868\n",
      "cost after 800  iterations: 2.2928290549612274\n",
      "cost after 850  iterations: 2.2925436174549594\n",
      "cost after 900  iterations: 2.292268800401521\n",
      "cost after 950  iterations: 2.2920037187983544\n",
      "cost after 1000  iterations: 2.2917476040830125\n",
      "cost after 1050  iterations: 2.291499783642823\n",
      "cost after 1100  iterations: 2.291259664776423\n",
      "cost after 1150  iterations: 2.291026721972913\n",
      "cost after 1200  iterations: 2.2908004867008196\n",
      "cost after 1250  iterations: 2.290580539122162\n",
      "cost after 1300  iterations: 2.2903665013020156\n",
      "cost after 1350  iterations: 2.290158031593564\n",
      "cost after 1400  iterations: 2.2899548199570203\n",
      "cost after 1450  iterations: 2.28975658402795\n",
      "cost after 1500  iterations: 2.2895630657923483\n",
      "cost after 1550  iterations: 2.289374028757211\n",
      "cost after 1600  iterations: 2.289189255528815\n",
      "cost after 1650  iterations: 2.2890085457289167\n",
      "cost after 1700  iterations: 2.2888317141928334\n",
      "cost after 1750  iterations: 2.288658589404159\n",
      "cost after 1800  iterations: 2.2884890121292014\n",
      "cost after 1850  iterations: 2.2883228342209234\n",
      "cost after 1900  iterations: 2.2881599175674223\n",
      "cost after 1950  iterations: 2.288000133164236\n",
      "cost after 2000  iterations: 2.287843360293203\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_predicted_train,Y_predicted_test=model(0.1,X_train,Y_train,X_test,Y_test,iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted_train=Y_predicted_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=confusion_matrix(Y_test,Y_predicted_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=confusion_matrix(Y_train,Y_predicted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 321,  691,  877,  696,  513,  883,  519,  277,  445,  701],\n",
       "       [ 765, 1746,  200,  533,  181,  193,  622, 1145, 1168,  189],\n",
       "       [ 966,  719,  335,  445,  411,  582,  483,  534,  941,  542],\n",
       "       [ 366,  519,  468,  592,  652,  443,  805,  623, 1256,  407],\n",
       "       [ 639,  722,  538,  698,  481,  677,  545,  723,  157,  662],\n",
       "       [ 646,  618,  559,  641,  384,  409,  235,  615,  700,  614],\n",
       "       [ 621,  866,  306, 1560,  416,  266,  310,  394,  666,  513],\n",
       "       [ 459,  987, 1401,  291, 1076,  591,  547,  462,  233,  218],\n",
       "       [ 353,  766,  441,  624,  644,  534,  833,  528,  541,  587],\n",
       "       [ 454,  458,  397,  442,  556, 1172,  771,  586,  401,  712]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 980,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 1135,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0, 1032,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0, 1010,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,  982,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,  892,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  958,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1028,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  974,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 1009]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy ,recall ,precision\n",
    "#for zero\n",
    "TP=test[0,0]\n",
    "FP=np.sum(test[0,1:],axis=0)\n",
    "TN=np.sum(test[1:,1:])\n",
    "FN=np.sum(test[1:,0])\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "recall=(TP)/(TP+FN)\n",
    "precision=(TP)/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For zero:\n",
      "Accuracy: 1.0 Recall : 1.0 Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"For zero:\")\n",
    "print(\"Accuracy: \"+str(accuracy)+\" Recall : \"+str(recall)+\" Precision: \"+str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
