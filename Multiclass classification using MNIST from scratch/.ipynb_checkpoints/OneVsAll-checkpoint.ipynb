{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist.loader import MNIST\n",
    "import numpy as np\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    mnist=MNIST('dataset')\n",
    "    ##train data\n",
    "    train_images,train_labels=mnist.load_training()\n",
    "    train_images=np.asarray(train_images)\n",
    "    train_labels=np.asarray(train_labels)\n",
    "    train_labels=train_labels.reshape([train_labels.shape[0],1])\n",
    "    #print(mnist.display(train_images[5]))\n",
    "    ##test data\n",
    "    test_images,test_labels=mnist.load_testing()\n",
    "    test_images=np.asarray(test_images)\n",
    "    test_labels=np.asarray(test_labels)\n",
    "    test_labels=test_labels.reshape([test_labels.shape[0],1])\n",
    "    return train_images,train_labels,test_images,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(digit,Y_train,Y_test):\n",
    "    #train\n",
    "    Y_tr=np.where(Y_train==digit,1,0)\n",
    "    \n",
    "    #test\n",
    "    Y_t=np.where(Y_test==digit,1,0)\n",
    "    return Y_tr,Y_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_normalization(X_train,X_test):\n",
    "    X_train=X_train/255\n",
    "    X_test=X_test/255\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n):\n",
    "    #theta=np.random.randint(-1,2,size=[n,1])\n",
    "    theta=np.zeros([n,1])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    hx=1/(1+(np.exp(-z)))\n",
    "    return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(hx,X,y):\n",
    "    m=y.shape[1]\n",
    "    cost=-((1/m)*np.sum((y*np.log(hx)+(1-y)*(np.log(1-hx))))) \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_of_cost(X,hx,y):\n",
    "    m=y.shape[1]\n",
    "    d_theeta=(1/m)*(np.sum(X*(hx-y),axis=1,keepdims=True))\n",
    "    return d_theeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X):\n",
    "    z=np.dot(theta.T,X)\n",
    "    hx =sigmoid(z)     \n",
    "    return hx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(hx):\n",
    "    m = hx.shape[1]\n",
    "    Y_prediction=hx.argmax(axis=1)\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y_actual, Y_predicted):\n",
    "    classes= np.unique(np.concatenate((Y_actual,Y_predicted)))\n",
    "    confusion_mtx = np.empty((len(classes),len(classes)),dtype=np.int)\n",
    "    for i,a in enumerate(classes):\n",
    "        for j,p in enumerate(classes):\n",
    "            confusion_mtx[i,j] = np.where((Y_actual==a)*(Y_predicted==p))[0].shape[0]\n",
    "    return confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(alpha,X_train,Y_train,X_test,Y_test,num_of_iterations):\n",
    "    m=Y_train.shape[1]\n",
    "    all_hx_train_list=[]\n",
    "    all_hx_test_list=[]\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    for i in range(0,10):\n",
    "        digit=i\n",
    "        Y_train,Y_test=one_vs_all(digit,Y_train,Y_test)\n",
    "        print (\"For \" +str(i))\n",
    "        hypothesis_train,hypothesis_test=binary_classification(alpha,X_train,Y_train,X_test,Y_test,num_of_iterations)\n",
    "        all_hx_train_list.append(hypothesis_train)\n",
    "        all_hx_test_list.append(hypothesis_test)\n",
    "        \n",
    "    #train\n",
    "    all_hx_train=np.array( all_hx_train_list)    \n",
    "    all_hx_train=all_hx_train.reshape(all_hx_train.shape[2],all_hx_train.shape[0])\n",
    "    Y_predicted_train=predict(all_hx_train)\n",
    "    Y_predicted_train=Y_predicted_train.reshape(1,Y_predicted_train.shape[0])\n",
    "    #test\n",
    "    all_hx_test=np.array( all_hx_test_list)    \n",
    "    all_hx_test=all_hx_test.reshape(all_hx_test.shape[2],all_hx_test.shape[0])\n",
    "    Y_predicted_test=predict(all_hx_test)\n",
    "    Y_predicted_test=Y_predicted_test.reshape(1,Y_predicted_test.shape[0])\n",
    "    \n",
    "    return all_hx_train,Y_predicted_train,Y_predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification(alpha,X_train,Y_train,X_test,Y_test,num_of_iterations):\n",
    "    costs=[]\n",
    "    theta=initialize_parameters(X_train.shape[0])\n",
    "    prev_weights=np.copy(theta)\n",
    "    for i in range(num_of_iterations):\n",
    "        z=np.dot(theta.T,X_train)\n",
    "        hx=sigmoid(z)\n",
    "        J=cost(hx,X_train,Y_train)\n",
    "        der=derivative_of_cost(X_train,hx,Y_train)\n",
    "        theta=theta-(alpha)*(der)\n",
    "        if i % 50 == 0:\n",
    "            costs.append(J)\n",
    "            print(\"cost after \"+str(i)+\" iterations\"+str(J))\n",
    "    hypothesis_train = hypothesis(theta, X_train)\n",
    "    hypothesis_test = hypothesis(theta, X_test)\n",
    "    return hypothesis_train,hypothesis_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "X_train,Y_train,X_test,Y_test=load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25b68f0fc88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view data\n",
    "print(Y_train[4])\n",
    "imshow(X_train[4].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "X_train,X_test=max_normalization(X_train,X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 60000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append train\n",
    "X=np.ones([X_train.shape[0],1]) \n",
    "X_train=np.append(X,X_train,axis=1) #(m,n)\n",
    "X_train=X_train.T #(n,m)\n",
    "Y_train=Y_train.T #(1,m)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append test\n",
    "X=np.ones([X_test.shape[0],1]) \n",
    "X_test=np.append(X,X_test,axis=1) #(m,n)\n",
    "X_test=X_test.T #(n,m)\n",
    "Y_test=Y_test.T #(1,m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 60000)\n",
      "(1, 60000)\n",
      "For 0\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6665795416781446\n",
      "cost after 100 iterations0.6423646582982208\n",
      "cost after 150 iterations0.6202763592080887\n",
      "cost after 200 iterations0.6001066296947183\n",
      "cost after 250 iterations0.5816656230201736\n",
      "cost after 300 iterations0.5647811324844361\n",
      "cost after 350 iterations0.5492977000659343\n",
      "cost after 400 iterations0.5350755025935159\n",
      "cost after 450 iterations0.5219891230772183\n",
      "For 1\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6665795416781446\n",
      "cost after 100 iterations0.6423646582982208\n",
      "cost after 150 iterations0.6202763592080887\n",
      "cost after 200 iterations0.6001066296947183\n",
      "cost after 250 iterations0.5816656230201736\n",
      "cost after 300 iterations0.5647811324844361\n",
      "cost after 350 iterations0.5492977000659343\n",
      "cost after 400 iterations0.5350755025935159\n",
      "cost after 450 iterations0.5219891230772183\n",
      "For 2\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 3\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 4\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 5\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 6\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 7\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 8\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n",
      "For 9\n",
      "cost after 0 iterations0.6931471805599453\n",
      "cost after 50 iterations0.6501467465335781\n",
      "cost after 100 iterations0.6111260777269865\n",
      "cost after 150 iterations0.5756903179038589\n",
      "cost after 200 iterations0.5434732494443996\n",
      "cost after 250 iterations0.5141396994256621\n",
      "cost after 300 iterations0.4873860511345663\n",
      "cost after 350 iterations0.4629394234055263\n",
      "cost after 400 iterations0.44055598829565945\n",
      "cost after 450 iterations0.42001879284960086\n"
     ]
    }
   ],
   "source": [
    "hx,Y_predicted_train,Y_predicted_test=model(0.0001,X_train,Y_train,X_test,Y_test,num_of_iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=confusion_matrix(Y_train, Y_predicted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 830,  348,  809,  331,  853,  324,  923,  298,  919,  288],\n",
       "       [ 989,  381,  923,  356, 1043,  418,  968,  324, 1007,  333],\n",
       "       [ 865,  322,  808,  304,  919,  310,  902,  314,  881,  333],\n",
       "       [ 837,  349,  832,  362,  939,  356,  865,  313,  934,  344],\n",
       "       [ 847,  325,  812,  303,  853,  314,  886,  314,  880,  308],\n",
       "       [ 795,  296,  744,  322,  803,  305,  780,  263,  831,  282],\n",
       "       [ 924,  313,  784,  292,  904,  302,  852,  318,  895,  334],\n",
       "       [ 914,  373,  866,  323,  982,  372,  863,  318,  938,  316],\n",
       "       [ 882,  291,  791,  302,  902,  326,  825,  317,  902,  313],\n",
       "       [ 883,  312,  849,  319,  884,  341,  820,  335,  891,  315]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=confusion_matrix(Y_test, Y_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy ,recall ,precision\n",
    "#for zero\n",
    "TP=test[0,0]\n",
    "FP=np.sum(test[0,1:],axis=0)\n",
    "TN=np.sum(test[1:,1:])\n",
    "FN=np.sum(test[1:,0])\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "recall=(TP)/(TP+FN)\n",
    "precision=(TP)/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for one\n",
    "TP=test[1,1]\n",
    "FP=np.sum(test[1,1:],axis=0)+test[1,0]\n",
    "TN=np.sum(test[2:,2:])+test[1,0]\n",
    "FN=np.sum(test[1:,0])\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "recall=(TP)/(TP+FN)\n",
    "precision=(TP)/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09402460456942004"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0861513687600644"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518047438982468"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
